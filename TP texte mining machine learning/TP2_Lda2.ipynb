{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation pour des Données Textes\n",
    "\n",
    "Dans ce TP \n",
    "\n",
    "* Appliquer des techniques de prétraitement standard sur les données textuelles Wikipedia en utilisant Pandas\n",
    "* Utiliser  Gensim pour adapter un modèle d'allocation latente de Dirichlet (LDA)\n",
    "* Explorer et interpréter les résultats, y compris les mots-clés de sujet et les assignations de sujets pour les documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prétraitement des données texte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "df = pandas.read_csv('people_wiki.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text = df.drop(columns=['URI', 'name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the regular expression library\n",
    "import re\n",
    "# Remove punctuation\n",
    "Text['text_processed'] = \\\n",
    "Text['text'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "# Convert the titles to lowercase\n",
    "Text['text_processed'] = \\\n",
    "Text['text_processed'].map(lambda x: x.lower())\n",
    "# Print out the first rows of papers\n",
    "Text['text_processed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the wordcloud library\n",
    "from wordcloud import WordCloud\n",
    "# Join the different processed titles together.\n",
    "long_string = ','.join(list(Text['text_processed'].values))\n",
    "# Create a WordCloud object\n",
    "wordcloud = WordCloud(background_color=\"white\", max_words=5000, contour_width=3, contour_color='steelblue')\n",
    "# Generate a word cloud\n",
    "wordcloud.generate(long_string)\n",
    "# Visualize the word cloud\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "data = Text.text_processed.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "# remove stop words\n",
    "data_words = remove_stopwords(data_words)\n",
    "print(data_words[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "# Create Corpus\n",
    "texts = data_words\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "# View\n",
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "# number of topics\n",
    "num_topics = 10\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics)\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_topic(topic_number, topn=50):\n",
    "    \"\"\"\n",
    "    accept a user-supplied topic number and\n",
    "    print out a formatted list of the top terms\n",
    "    \"\"\"\n",
    "        \n",
    "    print(u'{:20} {}'.format(u'term', u'frequency') + u'\\n')\n",
    "\n",
    "    for term, frequency in lda_model.show_topic(topic_number, topn):\n",
    "        print(u'{:20} {:.3f}'.format(term, round(frequency, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_topic(1,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifier lesTopiques par mots-clés\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 2: (2 pts)\n",
    "Quelle est la somme des probabilités assignées aux 50 premiers mots du troisième topique?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tapez votre code ici\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons les 10 premiers mots pour chaque topique pour voir si nous pouvons identifier n'importe quels thèmes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term                 frequency\n",
      "\n",
      "league               0.012\n",
      "played               0.012\n",
      "season               0.012\n",
      "football             0.009\n",
      "club                 0.007\n",
      "team                 0.007\n",
      "first                0.007\n",
      "coach                0.007\n",
      "born                 0.006\n",
      "university           0.005\n"
     ]
    }
   ],
   "source": [
    "explore_topic(2, topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous proposons les thèmes suivants pour chaque topique:\n",
    "\n",
    "- topic 0: Music, TV, and film\n",
    "- topic 1: Team sports\n",
    "- topic 2: Art and publishing\n",
    "- topic 3: American college and politics\n",
    "- topic 4: International athletics\n",
    "- topic 5: International music \n",
    "- topic 6: Science and research \n",
    "- topic 7: Business  \n",
    "- topic 8: Great Britain and Australia  \n",
    "- topic 9: General politics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "themes = ['iMusic, TV, and film','Team sports','Art and publishing','American college and politics',' International athletics','International music', \\\n",
    "         'Science and research','Business','Great Britain and Australia','General politics']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributions de topique pour certains exemples de documents\n",
    "\n",
    "\n",
    "LDA se base sur le modèle mixte, ce qui signifie que chaque document peut partiellement appartenir à plusieurs topiques différents. Pour chaque document, l'appartenance à un topic est exprimée sous la forme d'un vecteur de poids égal à un; L'importance de chaque poids indique le degré auquel le document représente ce sujet particulier.\n",
    "\n",
    "Nous allons explorer cela dans notre modèle  en examinant les distributions des topics pour quelques exemples d'articles Wikipedia de notre ensemble de données. Nous devrions trouver que ces articles ont les poids les plus élevés sur les topics dont les thèmes sont les plus important pour le topique de l'article - par exemple, nous nous attendons d'un article sur un homme de politique d'accorder un poids relativement élevé sur des topiques liés au gouvernement, un article sur un athlète devrait mettre plus de poids sur des topiques liés aux sports...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obama = df [df['name'] == 'Barack Obama']\n",
    "data1 = obama.text.values.tolist()\n",
    "data_words1 = list(sent_to_words(data1))\n",
    "# remove stop words\n",
    "data_words1 = remove_stopwords(data_words1)\n",
    "print(data_words1[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "id2word1 = corpora.Dictionary(data_words1)\n",
    "# Create Corpus\n",
    "texts1 = data_words1\n",
    "# Term Document Frequency\n",
    "corpus1 = [id2word.doc2bow(text) for text in texts1]\n",
    "vect=lda_model[corpus1]\n",
    "\n",
    "vect[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 3: (3 pts)\n",
    "\n",
    "Quel est le topique le plus étroitement lié à l'article sur l'ancien président américain George W. Bush? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tapez votre code ici\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "    \n",
    "LDAvis_prepared"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
